{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gymnasium imports\n",
    "import gymnasium as gym \n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "\n",
    "import pygame\n",
    "import pygame.gfxdraw\n",
    "\n",
    "# Import helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Import stable baselines\n",
    "# Probably not needed\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([0 1], [100  10], (2,), int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(low = np.array([0, 1]), high = np.array([100, 10]), dtype = np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SS_Mngmt_Env(Env):\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "    \n",
    "    # Define the action and observation space\n",
    "    def __init__(self, render_mode = None):\n",
    "\n",
    "        self.I0 = 30 # Initial stock level\n",
    "        self.stockout_cost = 100 # Cost of stockout\n",
    "        self.expected_demand = 6 # Expected demand for production\n",
    "\n",
    "        # Demand for production --> random for now\n",
    "        self.demand = self.expected_demand + random.randint(-3, 3)\n",
    "\n",
    "        # Order delay and queue\n",
    "        self.order_delay = 3\n",
    "        self.order_queue = deque(maxlen = self.order_delay)\n",
    "\n",
    "        # To implement\n",
    "        # self.order_cost = 10 # Cost of ordering stock\n",
    "        # self.holding_cost = 1 # Cost of holding stock\n",
    "        # unit cost\n",
    "        # storage capacities\n",
    "        # campaign size\n",
    "        \n",
    "        # Define action space\n",
    "        # Change the action space for different campaign sizes\n",
    "        self.action_space = Discrete(10)\n",
    "        \n",
    "        # Define observation space (Stock level) --> to add expected demand, etc.\n",
    "        self.observation_space = Box(low = np.array([0]), \n",
    "                                     high = np.array([100]),\n",
    "                                     dtype = np.int64)\n",
    "\n",
    "        # Define the initial state\n",
    "        self.state = np.array(self.I0, self.expected_demand)\n",
    "\n",
    "        # Length of the episode\n",
    "        self.episode_length = 29\n",
    "\n",
    "        # History\n",
    "        self.stock_history = []\n",
    "        self.demand_history = []\n",
    "        self.order_history = []\n",
    "\n",
    "        # Empty dataframe for plotting the history\n",
    "        self.history = pd.DataFrame(columns = ['Stock Level', 'Order', 'Demand'])\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "        self.screen_initialized = False\n",
    "\n",
    "\n",
    "    # Defining the step function\n",
    "    def step(self, action):\n",
    "        # Returns the next state, reward and whether the episode is done\n",
    "\n",
    "        # Initialize the reward\n",
    "        reward = 0\n",
    "\n",
    "        # Subtract the demand from the stock\n",
    "        self.state = self.state - self.demand\n",
    "\n",
    "        # To Do: Implement the cost of ordering stock\n",
    "        # To Do: Campaign Size\n",
    "\n",
    "        # Add the order to the queue\n",
    "        self.order_queue.append(action)\n",
    "\n",
    "        # If there are enough steps passed since the order was placed, add the order to the stock\n",
    "        if len(self.order_queue) == self.order_delay:\n",
    "            self.state += self.order_queue.popleft()\n",
    "\n",
    "        # Check if the stock level is negative\n",
    "        if self.state < 0:\n",
    "            # If the stock level is negative, the cost is the stockout cost\n",
    "            reward = -self.stockout_cost\n",
    "\n",
    "        # Calculate the cost of the stock\n",
    "        # Reward is negative since we want to minimize the cost\n",
    "        reward = float(reward -(self.state))\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self.episode_length == 0\n",
    "\n",
    "        # Decrease the episode length\n",
    "        self.episode_length -= 1\n",
    "\n",
    "        obs = np.array([self.state])\n",
    "\n",
    "        # Append the state to the history\n",
    "        self.stock_history.append(self.state)\n",
    "        self.demand_history.append(self.demand)\n",
    "\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        # Check if the episode is truncated\n",
    "        truncated = False\n",
    "\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is not None:\n",
    "            if self.render_mode == \"human\":\n",
    "                self.render_human()\n",
    "\n",
    "    # def render_human(self):\n",
    "    #     # Render the environment\n",
    "    #     # Provide a visual representation of the environment the stock level\n",
    "    #     # Stock level in y axis and time in x axis\n",
    "\n",
    "    #     plt.clf()\n",
    "        \n",
    "    #     plt.plot(self.stock_history)\n",
    "    #     plt.ylabel('Stock Level')\n",
    "    #     plt.xticks(np.arange(0, 30, step=5))\n",
    "    #     plt.yticks(np.arange(0, 100, step=10))\n",
    "    #     plt.xlabel('Time')\n",
    "    #     plt.draw()\n",
    "    #     plt.pause(0.01)\n",
    "        \n",
    "    #     return\n",
    "    \n",
    "    def render_human(self):\n",
    "\n",
    "        if not self.screen_initialized:\n",
    "            # Initialize Pygame only once\n",
    "            pygame.init()\n",
    "            self.width, self.height = 800, 600\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "            self.font = pygame.font.SysFont('Arial', 18)\n",
    "            self.screen_initialized = True\n",
    "\n",
    "        # Clear the screen\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        # Draw axes\n",
    "        pygame.draw.line(self.screen, (0, 0, 0), (50, self.height - 50), (self.width - 50, self.height - 50))  # x-axis\n",
    "        pygame.draw.line(self.screen, (0, 0, 0), (50, self.height - 50), (50, 50))  # y-axis\n",
    "\n",
    "        # Add labels to the axes\n",
    "        x_label = self.font.render('Iterations', True, (0, 0, 0))\n",
    "        y_label = self.font.render('Stock Level', True, (0, 0, 0))\n",
    "        self.screen.blit(x_label, (self.width // 2, self.height - 30))\n",
    "        self.screen.blit(y_label, (10, self.height // 2))\n",
    "\n",
    "        # Rotate the y-axis label\n",
    "        y_label = pygame.transform.rotate(y_label, 90)\n",
    "\n",
    "        # Draw grid lines\n",
    "        for x in range(100, self.width - 50, 50):\n",
    "            pygame.draw.line(self.screen, (200, 200, 200), (x, 50), (x, self.height - 50))\n",
    "        for y in range(100, self.height - 50, 50):\n",
    "            pygame.draw.line(self.screen, (200, 200, 200), (50, y), (self.width - 50, y))\n",
    "\n",
    "        # Scale the history to fit the window\n",
    "        if self.stock_history:\n",
    "            max_stock = max(self.stock_history) if self.stock_history else 1\n",
    "            scaled_history = [(i * (self.width - 100) / len(self.stock_history) + 50,\n",
    "                               self.height - (s * (self.height - 100) / max_stock + 50)) for i, s in enumerate(self.stock_history)]\n",
    "\n",
    "            # Draw the history\n",
    "            for i in range(1, len(scaled_history)):\n",
    "                pygame.draw.line(self.screen, (0, 0, 0), scaled_history[i-1], scaled_history[i], 2)\n",
    "\n",
    "            # Draw data points\n",
    "            for point in scaled_history:\n",
    "                pygame.draw.circle(self.screen, (0, 0, 255), (int(point[0]), int(point[1])), 5)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Pause for a short period to allow the plot to update\n",
    "        pygame.time.wait(200)\n",
    "\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "\n",
    "    def reset(self, seed = None):\n",
    "        # Reset the state of the environment back to an initial state\n",
    "\n",
    "        super().reset(seed = seed) # Reset the seed\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        # Reset the state\n",
    "        self.state = 50 + random.randint(-20, 20)\n",
    "\n",
    "        # Reset the episode length\n",
    "        self.episode_length = 30\n",
    "\n",
    "        # Reset the order queue\n",
    "        self.order_queue.clear()\n",
    "\n",
    "        # Define the initial state\n",
    "        self.state = np.array(self.I0, self.expected_demand)\n",
    "\n",
    "        obs = np.array([self.state])\n",
    "\n",
    "        # # Append history to the dataframe\n",
    "        # self.history['Stock Level'] = self.stock_history\n",
    "        # self.history['Order'] = self.stock_history\n",
    "        # self.history['Demand'] = self.demand_history\n",
    "\n",
    "        # Reset the history\n",
    "        self.stock_history = []\n",
    "        self.order_history = []\n",
    "        self.demand_history = []\n",
    "\n",
    "        # Placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        return obs, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testng the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = SS_Mngmt_Env(render_mode=\"human\")\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info, _ = env.step(action)\n",
    "        score+=reward\n",
    "\n",
    "        print('Step:{} Score:{} Stock:{} Order:{} Demand:{}'.format(env.episode_length, score, n_state, action, env.demand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info, _ = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{} Stock:{} Last Order:{}'.format(episode, score, n_state, action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model_path = os.path.join('Training', 'Models', 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = SS_Mngmt_Env(render_mode=\"human\")\n",
    "\n",
    "# wrapping the environment in a vectorized environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_10\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 6972 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4051         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074953516 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | -9.62e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+05     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    value_loss           | 1.81e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3607        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004483441 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | -0.00885    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+05    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 2.14e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3409        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005954098 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.00033     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.03e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 1.69e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3299         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042079687 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.00103      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.38e+04     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 1.88e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3226         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058466396 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.000403     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.27e+04     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.8e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3196         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125623485 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.000115     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.53e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    value_loss           | 1.38e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3168         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088694515 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.000547     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.54e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 1.66e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3132       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01059019 |\n",
      "|    clip_fraction        | 0.0606     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.24      |\n",
      "|    explained_variance   | 4.05e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.37e+04   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00855   |\n",
      "|    value_loss           | 1.65e+05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3106         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063608103 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 8.2e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.97e+04     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 1.5e+05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3094        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006726816 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 1.86e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.6e+04     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 1.54e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3089        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008965317 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 9.98e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.02e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3084        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008580892 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 4.39e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37e+04    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3078        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010794568 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 4.32e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.34e+04    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 1.26e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3073        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012245944 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 7.28e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.48e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 1.43e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3066         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047676517 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.000126     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.81e+04     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3062        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011549111 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 4.91e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.61e+04    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3057        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009700154 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 5.99e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.26e+04    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3054        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010980043 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 7.39e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.28e+04    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    value_loss           | 1.16e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3049        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011032626 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 1.26e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.02e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    value_loss           | 1.33e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3045        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006775202 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 5.19e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.97e+04    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3042        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013050998 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 5.13e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.07e+04    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    value_loss           | 1.23e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3040        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007031262 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 6.2e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.4e+04     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3038        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008856131 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 4.95e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.28e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 1.17e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3036        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010424927 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 3.08e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33e+04    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3034        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011205988 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 5.48e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06e+04    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    value_loss           | 9.52e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3031        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010097191 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.000141    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.32e+04    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 1.07e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3030        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008995382 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.000101    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.21e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    value_loss           | 1.01e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3028        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010593755 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.00342     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.01e+04    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 9.25e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3026        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566156 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 2.4e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.31e+04    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    value_loss           | 8.92e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3025         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063111736 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 2.92e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.59e+04     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 7.95e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3024        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831597 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 5.36e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.41e+04    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    value_loss           | 8.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3023        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009128401 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 5.07e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+04    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 5.98e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3022        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011223185 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 3.7e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61e+04    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    value_loss           | 6.22e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3020       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00654277 |\n",
      "|    clip_fraction        | 0.0462     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.1       |\n",
      "|    explained_variance   | 6.08e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.9e+04    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    value_loss           | 6.15e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3019         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062170024 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.0027       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48e+04     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 6.73e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3018        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007505824 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.000457    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56e+04    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 5.03e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3017         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077863275 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.00143      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+04     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 5.57e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3016        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011905161 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | -1.19e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+04    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    value_loss           | 6.04e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3015        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009336876 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+04    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    value_loss           | 4.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3014        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009806874 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+04     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 4.93e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3014        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009895947 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+04    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    value_loss           | 5.92e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3013        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009981966 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.2e+04     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 6.06e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3012       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03408669 |\n",
      "|    clip_fraction        | 0.088      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | 4.77e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.92e+04   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0018    |\n",
      "|    value_loss           | 4.05e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3011        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007019987 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43e+04    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3011        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009868187 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 2.98e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+04    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 3.44e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3011        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017131329 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+04    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 3.18e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3010        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010156022 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 2.98e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+04    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 4.43e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3010        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011607186 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00235     |\n",
      "|    value_loss           | 3.01e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x3021bf860>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasrenfer/miniconda3/envs/rl-course/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-905.0, -971.0, -917.0, -963.0, -861.0], [31, 31, 31, 31, 31])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO.load(model_path, env = env)\n",
    "\n",
    "env = SS_Mngmt_Env(render_mode=\"human\")\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes=5, render=True, return_episode_rewards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
